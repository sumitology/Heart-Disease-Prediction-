# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i2DQMsxGRSw-vWmA0kyiNmQUxk0hKVRa
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score

# Function to load and preprocess the dataset
def load_and_preprocess_data(filepath):
    df = pd.read_csv(filepath)
    df = df.drop_duplicates()  # Remove duplicates
    df = df.dropna()  # Drop missing values (more sophisticated imputation can be added)

    # Feature scaling
    scaler = StandardScaler()
    features = df.drop(columns='target', axis=1)
    scaled_features = scaler.fit_transform(features)
    df_scaled = pd.DataFrame(scaled_features, columns=features.columns)
    df_scaled['target'] = df['target'].values

    return df_scaled

# Function to split the dataset
def split_dataset(df):
    X = df.drop(columns='target', axis=1)
    Y = df['target']
    return train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)

# Function to train and evaluate a model
def train_and_evaluate_model(model, X_train, X_test, Y_train, Y_test):
    model.fit(X_train, Y_train)
    train_accuracy = accuracy_score(Y_train, model.predict(X_train))
    test_accuracy = accuracy_score(Y_test, model.predict(X_test))

    print(f"\nModel: {model.__class__.__name__}")
    print(f"Training Accuracy: {train_accuracy:.4f}")
    print(f"Test Accuracy: {test_accuracy:.4f}")

    # Classification report and confusion matrix
    print("\nClassification Report:")
    print(classification_report(Y_test, model.predict(X_test)))

    print("Confusion Matrix:")
    cm = confusion_matrix(Y_test, model.predict(X_test))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Healthy', 'Defective'], yticklabels=['Healthy', 'Defective'])
    plt.title(f'Confusion Matrix - {model.__class__.__name__}')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

    # ROC Curve
    y_probs = model.predict_proba(X_test)[:, 1]
    fpr, tpr, thresholds = roc_curve(Y_test, y_probs)
    plt.plot(fpr, tpr, label=f'{model.__class__.__name__} (AUC = {roc_auc_score(Y_test, y_probs):.4f})')
    plt.plot([0, 1], [0, 1], linestyle='--')
    plt.title(f'ROC Curve - {model.__class__.__name__}')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    plt.show()

# Function for hyperparameter tuning using GridSearchCV
def hyperparameter_tuning(model, param_grid, X_train, Y_train):
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
    grid_search.fit(X_train, Y_train)
    print(f"Best parameters for {model.__class__.__name__}: {grid_search.best_params_}")
    return grid_search.best_estimator_

# Function for user-friendly prediction input
def make_prediction(model):
    print("Please enter the following patient information:")

    # Define feature names (make sure these match the columns in your dataset)
    features = {
        'Age': 'age',
        'Sex (1 for male, 0 for female)': 'sex',
        'Chest Pain Type (1-4)': 'chest_pain_type',
        'Resting Blood Pressure': 'resting_blood_pressure',
        'Cholesterol': 'cholesterol',
        'Fasting Blood Sugar (1 if > 120 mg/dl, 0 otherwise)': 'fasting_blood_sugar',
        'Resting Electrocardiographic Results (0-2)': 'resting_ecg_results',
        'Maximum Heart Rate Achieved': 'max_heart_rate',
        'Exercise Induced Angina (1 if present, 0 otherwise)': 'exercise_angina',
        'Oldpeak Depression': 'oldpeak_depression',
        'Slope of Peak Exercise ST Segment (1-3)': 'slope_exercise_st_segment',
        'Number of Major Vessels (0-3)': 'num_major_vessels',
        'Thalassemia (1-3)': 'thalassemia'
    }

    input_data = []

    # Collect input data from user
    for feature_name, column_name in features.items():
        while True:
            try:
                value = float(input(f"{feature_name}: "))
                input_data.append(value)
                break
            except ValueError:
                print("Invalid input. Please enter a numeric value.")

    # Convert the list to a numpy array and reshape it for prediction
    input_data_as_numpy_array = np.asarray(input_data).reshape(1, -1)

    # Make a prediction
    prediction = model.predict(input_data_as_numpy_array)

    # Interpret the prediction
    disease_status = "defective heart" if prediction[0] == 1 else "healthy heart"
    print(f"\nPrediction: The person has a {disease_status}.")

# Main execution
def main():
    filepath = '/content/heart_disease_data (1).csv'
    df = load_and_preprocess_data(filepath)

    X_train, X_test, Y_train, Y_test = split_dataset(df)

    # Model training and evaluation
    logistic_model = LogisticRegression()
    train_and_evaluate_model(logistic_model, X_train, X_test, Y_train, Y_test)

    rf_model = RandomForestClassifier(random_state=2)
    rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}
    rf_best_model = hyperparameter_tuning(rf_model, rf_params, X_train, Y_train)
    train_and_evaluate_model(rf_best_model, X_train, X_test, Y_train, Y_test)

    # Predictive system with user input
    make_prediction(logistic_model)

if __name__ == "__main__":
    main()